import argparse
import yaml
import torch
import os
import numpy as np
import glob

# å¯¼å…¥ä½ çš„æ¨¡å—
from model import ParallelUFNO
from visualizer import Visualizer

def load_config(config_path):
    with open(config_path, "r", encoding='utf-8') as f:
        return yaml.safe_load(f)

def main():
    parser = argparse.ArgumentParser(description="Generate Paper-Ready Visualizations")
    parser.add_argument("--config", type=str, default="config.yaml")
    parser.add_argument("--checkpoint", type=str, default="outputs/models_weights/best_model.pth")
    parser.add_argument("--output-dir", type=str, default="outputs/figures")
    # å¦‚æœä¸æŒ‡å®š filenameï¼Œè„šæœ¬ä¼šè‡ªåŠ¨åœ¨ data ç›®å½•ä¸‹éšä¾¿æ‰¾ä¸€ä¸ª
    parser.add_argument("--filename", type=str, default=None, help="Specific .npy filename to visualize") 
    parser.add_argument("--time-steps", type=int, nargs="+", default=[10, 50, 90], help="Time steps to plot")
    args = parser.parse_args()

    # 1. åŸºç¡€è®¾ç½®
    cfg = load_config(args.config)
    device = torch.device(cfg["training"]["device"] if torch.cuda.is_available() else "cpu")
    print(f"ğŸš€ Visualization running on {device}")

    # 2. åˆå§‹åŒ– Visualizer
    # å¯¹åº”ä½ çš„4ä¸ªé€šé“åç§°
    viz = Visualizer(
        output_dir=args.output_dir, 
        channel_names=["Temperature", "Austenite", "Ferrite_Pearlite", "Martensite"]
    )

    # 3. åŠ è½½ Mask (å¦‚æœæœ‰)
    mask = None
    mask_path = os.path.join("data/processed/npy_data", "geometry_mask.npy")
    if os.path.exists(mask_path):
        print("ğŸ­ Loading mask...")
        mask = torch.from_numpy(np.load(mask_path)).float().to(device)
        viz.plot_mask(mask) # ç”» Mask

    # 4. åŠ è½½æ¨¡å‹
    print("ğŸ—ï¸  Building model...")
    model = ParallelUFNO(
        n_modes=tuple(cfg["model"]["n_modes"]),
        hidden_channels=cfg["model"]["hidden_channels"],
        in_channels=cfg["model"]["in_channels"],
        out_channels=cfg["model"]["out_channels"],
        n_layers=cfg["model"]["n_layers"],
        encoder_name=cfg["model"]["encoder_name"],
        encoder_weights=None
    ).to(device)

    # åŠ è½½æƒé‡ (å¸¦ _metadata ä¿®å¤)
    if os.path.exists(args.checkpoint):
        print(f"ğŸ”„ Loading weights: {args.checkpoint}")
        state = torch.load(args.checkpoint, map_location=device, weights_only=False)
        if isinstance(state, dict):
            if "model_state_dict" in state: state = state["model_state_dict"]
            if "_metadata" in state: del state["_metadata"]
        model.load_state_dict(state, strict=False)
        model.eval()
    else:
        print(f"âŒ Checkpoint not found: {args.checkpoint}")
        return

    # 5. ç¡®å®šè¦ç”»å“ªä¸ªæ–‡ä»¶
    data_dir = "data/processed/npy_data"
    if args.filename:
        file_path = os.path.join(data_dir, args.filename)
    else:
        # è‡ªåŠ¨æ‰¾ä¸€ä¸ªåä¸º sim_... çš„æ–‡ä»¶
        files = glob.glob(os.path.join(data_dir, "sim_*.npy"))
        if not files:
            print("âŒ No data files found!")
            return
        file_path = files[0] # é»˜è®¤å–ç¬¬ä¸€ä¸ª
        print(f"ğŸ” Auto-selected file: {os.path.basename(file_path)}")

    # 6. åŠ è½½æ•´ä¸ªæ—¶é—´åºåˆ—æ•°æ®
    # Shape: [Time, Channels, H, W]
    try:
        full_data = np.load(file_path)
        print(f"ğŸ“¦ Loaded data shape: {full_data.shape}")
    except Exception as e:
        print(f"âŒ Error loading data: {e}")
        return

    # æ–‡ä»¶åå‰ç¼€ (ç”¨äºä¿å­˜å›¾ç‰‡)
    prefix = os.path.basename(file_path).replace(".npy", "")

    # 7. å¾ªç¯æŒ‡å®šçš„æ—¶é—´æ­¥è¿›è¡Œç»˜å›¾
    for t in args.time_steps:
        if t >= full_data.shape[0]:
            print(f"âš ï¸ Time step {t} out of range (Max {full_data.shape[0]-1}), skipping.")
            continue
            
        print(f"\nğŸ¨ Processing Time Step: {t} ...")
        
        # å‡†å¤‡è¾“å…¥ (t) å’Œ ç›®æ ‡ (t+1)
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬åš "t -> t+1" çš„é¢„æµ‹æ¼”ç¤º
        # Input: full_data[t]
        # Target: full_data[t+1] (å¦‚æœè¶Šç•Œå°±å– t)
        
        input_np = full_data[t]
        target_np = full_data[t+1] if t < full_data.shape[0]-1 else full_data[t]
        
        # è½¬ Tensor å¹¶åŠ  Batch ç»´åº¦ [1, C, H, W]
        # å¼ºåˆ¶åªå–å‰4ä¸ªé€šé“ (é€‚é…ä½ çš„æ–°æ¨¡å‹)
        x_in = torch.from_numpy(input_np[:4]).float().unsqueeze(0).to(device)
        y_target = torch.from_numpy(target_np[:4]).float().to(device) # è¿™é‡Œä¸éœ€è¦ batch ç»´åº¦ç»™ visualizer, åé¢å¤„ç†
        
        with torch.no_grad():
            out = model(x_in) # Model output: [1, 4, H, W] (Internal Softmax Applied)
            pred = out.squeeze(0) # å»æ‰ Batch -> [4, H, W]

        # --- è°ƒç”¨ Visualizer ç”»å›¾ ---
        
        # A. ç”» Comparison (æœ€é‡è¦)
        viz.plot_comparison(
            target=y_target, 
            pred=pred, 
            mask=mask, 
            time_step=t+1,  # å› ä¸ºæ˜¯é¢„æµ‹ t+1
            filename_prefix=prefix
        )
        
        # B. ç”» Single State (å•ç‹¬å±•ç¤ºçœŸå€¼ï¼Œç”¨äºå†™ Paper)
        # ç”»å¥¥æ°ä½“ (Austenite, Channel 1) å’Œ é©¬æ°ä½“ (Martensite, Channel 3)
        viz.plot_single_state(y_target, channel_idx=1, time_step=t+1, filename_prefix=prefix)
        viz.plot_single_state(y_target, channel_idx=3, time_step=t+1, filename_prefix=prefix)

    print(f"\nâœ… All visualizations saved to: {args.output_dir}")

if __name__ == "__main__":
    main()